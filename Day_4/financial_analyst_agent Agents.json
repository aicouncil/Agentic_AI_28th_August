{
  "nodes": [
    {
      "id": "calculator_0",
      "position": {
        "x": -159.30785734304726,
        "y": -111.22458437009524
      },
      "type": "customNode",
      "data": {
        "id": "calculator_0",
        "label": "Calculator",
        "version": 1,
        "name": "calculator",
        "type": "Calculator",
        "baseClasses": [
          "Calculator",
          "Tool",
          "StructuredTool",
          "Runnable"
        ],
        "category": "Tools",
        "description": "Perform calculations on response",
        "inputParams": [],
        "inputAnchors": [],
        "inputs": {},
        "outputAnchors": [
          {
            "id": "calculator_0-output-calculator-Calculator|Tool|StructuredTool|Runnable",
            "name": "calculator",
            "label": "Calculator",
            "description": "Perform calculations on response",
            "type": "Calculator | Tool | StructuredTool | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 149,
      "selected": false,
      "positionAbsolute": {
        "x": -159.30785734304726,
        "y": -111.22458437009524
      },
      "dragging": false
    },
    {
      "id": "codeInterpreterE2B_0",
      "position": {
        "x": 252.97301469140962,
        "y": -429.7897929352024
      },
      "type": "customNode",
      "data": {
        "id": "codeInterpreterE2B_0",
        "label": "Code Interpreter by E2B",
        "version": 1,
        "name": "codeInterpreterE2B",
        "type": "CodeInterpreter",
        "baseClasses": [
          "CodeInterpreter",
          "Tool",
          "StructuredTool",
          "Runnable"
        ],
        "category": "Tools",
        "description": "Execute code in a sandbox environment",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "E2BApi"
            ],
            "optional": true,
            "id": "codeInterpreterE2B_0-input-credential-credential",
            "display": true
          },
          {
            "label": "Tool Name",
            "name": "toolName",
            "type": "string",
            "description": "Specify the name of the tool",
            "default": "code_interpreter",
            "id": "codeInterpreterE2B_0-input-toolName-string",
            "display": true
          },
          {
            "label": "Tool Description",
            "name": "toolDesc",
            "type": "string",
            "rows": 4,
            "description": "Specify the description of the tool",
            "default": "Evaluates python code in a sandbox environment. The environment is long running and exists across multiple executions. You must send the whole script every time and print your outputs. Script should be pure python code that can be evaluated. It should be in python format NOT markdown. The code should NOT be wrapped in backticks. All python packages including requests, matplotlib, scipy, numpy, pandas, etc are available. Create and display chart using \"plt.show()\".",
            "id": "codeInterpreterE2B_0-input-toolDesc-string",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "toolName": "code_interpreter",
          "toolDesc": "Evaluates python code in a sandbox environment. The environment is long running and exists across multiple executions. You must send the whole script every time and print your outputs. Script should be pure python code that can be evaluated. It should be in python format NOT markdown. The code should NOT be wrapped in backticks. All python packages including requests, matplotlib, scipy, numpy, pandas, etc are available. Create and display chart using \"plt.show()\"."
        },
        "outputAnchors": [
          {
            "id": "codeInterpreterE2B_0-output-codeInterpreterE2B-CodeInterpreter|Tool|StructuredTool|Runnable",
            "name": "codeInterpreterE2B",
            "label": "CodeInterpreter",
            "description": "Execute code in a sandbox environment",
            "type": "CodeInterpreter | Tool | StructuredTool | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 556,
      "selected": false,
      "positionAbsolute": {
        "x": 252.97301469140962,
        "y": -429.7897929352024
      },
      "dragging": false
    },
    {
      "id": "writeFile_0",
      "position": {
        "x": 644.9193271798526,
        "y": -179.56866199112957
      },
      "type": "customNode",
      "data": {
        "id": "writeFile_0",
        "label": "Write File",
        "version": 1,
        "name": "writeFile",
        "type": "WriteFile",
        "baseClasses": [
          "WriteFile",
          "Tool",
          "StructuredTool",
          "Runnable"
        ],
        "category": "Tools",
        "description": "Write file to disk",
        "inputParams": [
          {
            "label": "Base Path",
            "name": "basePath",
            "placeholder": "C:\\Users\\User\\Desktop",
            "type": "string",
            "optional": true,
            "id": "writeFile_0-input-basePath-string",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "basePath": "C:\\Users\\vipul\\Desktop\\flowise_agent"
        },
        "outputAnchors": [
          {
            "id": "writeFile_0-output-writeFile-WriteFile|Tool|StructuredTool|Runnable",
            "name": "writeFile",
            "label": "WriteFile",
            "description": "Write file to disk",
            "type": "WriteFile | Tool | StructuredTool | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 284,
      "selected": false,
      "positionAbsolute": {
        "x": 644.9193271798526,
        "y": -179.56866199112957
      },
      "dragging": false
    },
    {
      "id": "supervisor_0",
      "position": {
        "x": -235.1688367472246,
        "y": 172.76393066210915
      },
      "type": "customNode",
      "data": {
        "id": "supervisor_0",
        "label": "Supervisor",
        "version": 3,
        "name": "supervisor",
        "type": "Supervisor",
        "baseClasses": [
          "Supervisor"
        ],
        "category": "Multi Agents",
        "inputParams": [
          {
            "label": "Supervisor Name",
            "name": "supervisorName",
            "type": "string",
            "placeholder": "Supervisor",
            "default": "Supervisor",
            "id": "supervisor_0-input-supervisorName-string",
            "display": true
          },
          {
            "label": "Supervisor Prompt",
            "name": "supervisorPrompt",
            "type": "string",
            "description": "Prompt must contains {team_members}",
            "rows": 4,
            "default": "You are a supervisor tasked with managing a conversation between the following workers: {team_members}.\nGiven the following user request, respond with the worker to act next.\nEach worker will perform a task and respond with their results and status.\nWhen finished, respond with FINISH.\nSelect strategically to minimize the number of steps taken.",
            "additionalParams": true,
            "id": "supervisor_0-input-supervisorPrompt-string",
            "display": true
          },
          {
            "label": "Summarization",
            "name": "summarization",
            "type": "boolean",
            "description": "Return final output as a summarization of the conversation",
            "optional": true,
            "additionalParams": true,
            "id": "supervisor_0-input-summarization-boolean",
            "display": true
          },
          {
            "label": "Recursion Limit",
            "name": "recursionLimit",
            "type": "number",
            "description": "Maximum number of times a call can recurse. If not provided, defaults to 100.",
            "default": 100,
            "additionalParams": true,
            "id": "supervisor_0-input-recursionLimit-number",
            "display": true
          }
        ],
        "inputAnchors": [
          {
            "label": "Tool Calling Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "description": "Only compatible with models that are capable of function calling: ChatOpenAI, ChatMistral, ChatAnthropic, ChatGoogleGenerativeAI, GroqChat. Best result with GPT-4 model",
            "id": "supervisor_0-input-model-BaseChatModel",
            "display": true
          },
          {
            "label": "Agent Memory",
            "name": "agentMemory",
            "type": "BaseCheckpointSaver",
            "description": "Save the state of the agent",
            "optional": true,
            "id": "supervisor_0-input-agentMemory-BaseCheckpointSaver",
            "display": true
          },
          {
            "label": "Input Moderation",
            "description": "Detect text that could generate harmful output and prevent it from being sent to the language model",
            "name": "inputModeration",
            "type": "Moderation",
            "optional": true,
            "list": true,
            "id": "supervisor_0-input-inputModeration-Moderation",
            "display": true
          }
        ],
        "inputs": {
          "supervisorName": "Supervisor",
          "supervisorPrompt": "You are a supervisor tasked with managing a conversation between the following workers: {team_members}.\nGiven the following user request, respond with the worker to act next.\nEach worker will perform a task and respond with their results and status.\nWhen finished, respond with FINISH.\nSelect strategically to minimize the number of steps taken.",
          "model": "{{chatOpenAI_0.data.instance}}",
          "agentMemory": "",
          "summarization": "",
          "recursionLimit": 100,
          "inputModeration": ""
        },
        "outputAnchors": [
          {
            "id": "supervisor_0-output-supervisor-Supervisor",
            "name": "supervisor",
            "label": "Supervisor",
            "description": "",
            "type": "Supervisor"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 488,
      "selected": false,
      "positionAbsolute": {
        "x": -235.1688367472246,
        "y": 172.76393066210915
      },
      "dragging": false
    },
    {
      "id": "worker_0",
      "position": {
        "x": 249.47430757748347,
        "y": 157.89757654171922
      },
      "type": "customNode",
      "data": {
        "id": "worker_0",
        "label": "Worker",
        "version": 2,
        "name": "worker",
        "type": "Worker",
        "hideOutput": true,
        "baseClasses": [
          "Worker"
        ],
        "category": "Multi Agents",
        "inputParams": [
          {
            "label": "Worker Name",
            "name": "workerName",
            "type": "string",
            "placeholder": "Worker",
            "id": "worker_0-input-workerName-string",
            "display": true
          },
          {
            "label": "Worker Prompt",
            "name": "workerPrompt",
            "type": "string",
            "rows": 4,
            "default": "You are a research assistant who can search for up-to-date info using search engine.",
            "id": "worker_0-input-workerPrompt-string",
            "display": true
          },
          {
            "label": "Format Prompt Values",
            "name": "promptValues",
            "type": "json",
            "optional": true,
            "acceptVariable": true,
            "list": true,
            "id": "worker_0-input-promptValues-json",
            "display": true
          },
          {
            "label": "Max Iterations",
            "name": "maxIterations",
            "type": "number",
            "optional": true,
            "id": "worker_0-input-maxIterations-number",
            "display": true
          }
        ],
        "inputAnchors": [
          {
            "label": "Tools",
            "name": "tools",
            "type": "Tool",
            "list": true,
            "optional": true,
            "id": "worker_0-input-tools-Tool",
            "display": true
          },
          {
            "label": "Supervisor",
            "name": "supervisor",
            "type": "Supervisor",
            "id": "worker_0-input-supervisor-Supervisor",
            "display": true
          },
          {
            "label": "Tool Calling Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "optional": true,
            "description": "Only compatible with models that are capable of function calling: ChatOpenAI, ChatMistral, ChatAnthropic, ChatGoogleGenerativeAI, ChatVertexAI, GroqChat. If not specified, supervisor's model will be used",
            "id": "worker_0-input-model-BaseChatModel",
            "display": true
          }
        ],
        "inputs": {
          "workerName": "Investment Calculator",
          "workerPrompt": "As a financial analyst specializing in investment calculations, your primary task is to accurately compute the percentage breakdowns of the user's investment portfolio. You are to use the calculator tool to analyze the provided investment data, determining the exact percentage each investment contributes to the total portfolio. Your calculations are essential for offering clarity and insight into the user's financial distribution.\n\nYour goal is to deliver accurate and clear percentage figures for each investment category.\n\n    Receive the investment data from the user, including the total investment amount and individual investment values.\n    Use the calculator tool to compute the percentage that each investment contributes to the total portfolio.\n    Ensure that your calculations are precise and free from errors.\n    Pass the calculated percentages to the Visualization Script Writer for further processing.\n\nAnnotations:\n\n    The instructions are now structured into a numbered list for better readability and execution.\n    Emphasized the importance of accuracy and error-free calculations.\n",
          "tools": [
            "{{calculator_0.data.instance}}"
          ],
          "supervisor": "{{supervisor_0.data.instance}}",
          "model": "",
          "promptValues": "",
          "maxIterations": ""
        },
        "outputAnchors": [],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 727,
      "selected": false,
      "positionAbsolute": {
        "x": 249.47430757748347,
        "y": 157.89757654171922
      },
      "dragging": false
    },
    {
      "id": "worker_1",
      "position": {
        "x": 760.2003180882749,
        "y": 150.34663114278544
      },
      "type": "customNode",
      "data": {
        "id": "worker_1",
        "label": "Worker",
        "version": 2,
        "name": "worker",
        "type": "Worker",
        "hideOutput": true,
        "baseClasses": [
          "Worker"
        ],
        "category": "Multi Agents",
        "inputParams": [
          {
            "label": "Worker Name",
            "name": "workerName",
            "type": "string",
            "placeholder": "Worker",
            "id": "worker_1-input-workerName-string",
            "display": true
          },
          {
            "label": "Worker Prompt",
            "name": "workerPrompt",
            "type": "string",
            "rows": 4,
            "default": "You are a research assistant who can search for up-to-date info using search engine.",
            "id": "worker_1-input-workerPrompt-string",
            "display": true
          },
          {
            "label": "Format Prompt Values",
            "name": "promptValues",
            "type": "json",
            "optional": true,
            "acceptVariable": true,
            "list": true,
            "id": "worker_1-input-promptValues-json",
            "display": true
          },
          {
            "label": "Max Iterations",
            "name": "maxIterations",
            "type": "number",
            "optional": true,
            "id": "worker_1-input-maxIterations-number",
            "display": true
          }
        ],
        "inputAnchors": [
          {
            "label": "Tools",
            "name": "tools",
            "type": "Tool",
            "list": true,
            "optional": true,
            "id": "worker_1-input-tools-Tool",
            "display": true
          },
          {
            "label": "Supervisor",
            "name": "supervisor",
            "type": "Supervisor",
            "id": "worker_1-input-supervisor-Supervisor",
            "display": true
          },
          {
            "label": "Tool Calling Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "optional": true,
            "description": "Only compatible with models that are capable of function calling: ChatOpenAI, ChatMistral, ChatAnthropic, ChatGoogleGenerativeAI, ChatVertexAI, GroqChat. If not specified, supervisor's model will be used",
            "id": "worker_1-input-model-BaseChatModel",
            "display": true
          }
        ],
        "inputs": {
          "workerName": "Visualization Script Writer",
          "workerPrompt": "As a data visualization specialist, your role is to convert numerical investment data into visually engaging and informative graphics. Using the code interpreter tool, you will develop a Python script that generates a pie chart or bar graph to visually represent the user's investment portfolio. Your work will assist the user in quickly understanding the distribution of their investments.\n\nYour goal is to create a clear and aesthetically pleasing visual representation of the investment data.\n\n    Utilize the percentage data provided by the Investment Calculator to write a Python script that generates a pie chart or bar graph.\n    Ensure the script is efficient, well-documented, and easy to execute.\n    The visualization should clearly depict each investment category's share of the total portfolio, with appropriate labels and color coding.\n    Pass the Python script to the Financial Summary Reporter along with the visualization output.\n\nAnnotations:\n\n    Instructions are organized into a numbered list for clarity.\n    Added emphasis on the script being well-documented and easy to execute.\n",
          "tools": [
            "{{codeInterpreterE2B_0.data.instance}}"
          ],
          "supervisor": "{{supervisor_0.data.instance}}",
          "model": "",
          "promptValues": "",
          "maxIterations": ""
        },
        "outputAnchors": [],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 727,
      "selected": false,
      "positionAbsolute": {
        "x": 760.2003180882749,
        "y": 150.34663114278544
      },
      "dragging": false
    },
    {
      "id": "worker_2",
      "position": {
        "x": 1359.8828465339116,
        "y": 134.50395506744368
      },
      "type": "customNode",
      "data": {
        "id": "worker_2",
        "label": "Worker",
        "version": 2,
        "name": "worker",
        "type": "Worker",
        "hideOutput": true,
        "baseClasses": [
          "Worker"
        ],
        "category": "Multi Agents",
        "inputParams": [
          {
            "label": "Worker Name",
            "name": "workerName",
            "type": "string",
            "placeholder": "Worker",
            "id": "worker_2-input-workerName-string",
            "display": true
          },
          {
            "label": "Worker Prompt",
            "name": "workerPrompt",
            "type": "string",
            "rows": 4,
            "default": "You are a research assistant who can search for up-to-date info using search engine.",
            "id": "worker_2-input-workerPrompt-string",
            "display": true
          },
          {
            "label": "Format Prompt Values",
            "name": "promptValues",
            "type": "json",
            "optional": true,
            "acceptVariable": true,
            "list": true,
            "id": "worker_2-input-promptValues-json",
            "display": true
          },
          {
            "label": "Max Iterations",
            "name": "maxIterations",
            "type": "number",
            "optional": true,
            "id": "worker_2-input-maxIterations-number",
            "display": true
          }
        ],
        "inputAnchors": [
          {
            "label": "Tools",
            "name": "tools",
            "type": "Tool",
            "list": true,
            "optional": true,
            "id": "worker_2-input-tools-Tool",
            "display": true
          },
          {
            "label": "Supervisor",
            "name": "supervisor",
            "type": "Supervisor",
            "id": "worker_2-input-supervisor-Supervisor",
            "display": true
          },
          {
            "label": "Tool Calling Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "optional": true,
            "description": "Only compatible with models that are capable of function calling: ChatOpenAI, ChatMistral, ChatAnthropic, ChatGoogleGenerativeAI, ChatVertexAI, GroqChat. If not specified, supervisor's model will be used",
            "id": "worker_2-input-model-BaseChatModel",
            "display": true
          }
        ],
        "inputs": {
          "workerName": "Financial Summary Reporter",
          "workerPrompt": "As a financial reporting expert, your task is to compile a concise and informative summary of the user's financial status. Using the write file tool, you will document the investment analysis and visualization in a comprehensive report. This report will serve as a valuable reference for the user, capturing both the numerical and visual aspects of their financial portfolio.\n\nYour goal is to provide a clear and insightful summary, along with the necessary files for future reference.\n\n    Use the visualization output and Python script from the Visualization Script Writer to create a summary report of the user's financial status.\n    Include key insights from the investment data, highlighting significant trends or noteworthy distributions.\n    Save the report and the Python script locally, ensuring they are easily accessible for the user.\n    Ensure the report is well-organized, professional, and provides a clear overview of the user's investments.\n\"",
          "tools": [
            "{{writeFile_0.data.instance}}"
          ],
          "supervisor": "{{supervisor_0.data.instance}}",
          "model": "{{chatOpenAI_1.data.instance}}",
          "promptValues": "",
          "maxIterations": ""
        },
        "outputAnchors": [],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 727,
      "selected": false,
      "positionAbsolute": {
        "x": 1359.8828465339116,
        "y": 134.50395506744368
      },
      "dragging": false
    },
    {
      "id": "chatOpenAI_0",
      "position": {
        "x": -703.0523571575214,
        "y": 79.38293016589085
      },
      "type": "customNode",
      "data": {
        "id": "chatOpenAI_0",
        "label": "ChatOpenAI",
        "version": 8.2,
        "name": "chatOpenAI",
        "type": "ChatOpenAI",
        "baseClasses": [
          "ChatOpenAI",
          "BaseChatModel",
          "BaseLanguageModel",
          "Runnable"
        ],
        "category": "Chat Models",
        "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "openAIApi"
            ],
            "id": "chatOpenAI_0-input-credential-credential",
            "display": true
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "default": "gpt-4o-mini",
            "id": "chatOpenAI_0-input-modelName-asyncOptions",
            "display": true
          },
          {
            "label": "Temperature",
            "name": "temperature",
            "type": "number",
            "step": 0.1,
            "default": 0.9,
            "optional": true,
            "id": "chatOpenAI_0-input-temperature-number",
            "display": true
          },
          {
            "label": "Streaming",
            "name": "streaming",
            "type": "boolean",
            "default": true,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-streaming-boolean",
            "display": true
          },
          {
            "label": "Max Tokens",
            "name": "maxTokens",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-maxTokens-number",
            "display": true
          },
          {
            "label": "Top Probability",
            "name": "topP",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-topP-number",
            "display": true
          },
          {
            "label": "Frequency Penalty",
            "name": "frequencyPenalty",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-frequencyPenalty-number",
            "display": true
          },
          {
            "label": "Presence Penalty",
            "name": "presencePenalty",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-presencePenalty-number",
            "display": true
          },
          {
            "label": "Timeout",
            "name": "timeout",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-timeout-number",
            "display": true
          },
          {
            "label": "Strict Tool Calling",
            "name": "strictToolCalling",
            "type": "boolean",
            "description": "Whether the model supports the `strict` argument when passing in tools. If not specified, the `strict` argument will not be passed to OpenAI.",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-strictToolCalling-boolean",
            "display": true
          },
          {
            "label": "Stop Sequence",
            "name": "stopSequence",
            "type": "string",
            "rows": 4,
            "optional": true,
            "description": "List of stop words to use when generating. Use comma to separate multiple stop words.",
            "additionalParams": true,
            "id": "chatOpenAI_0-input-stopSequence-string",
            "display": true
          },
          {
            "label": "BasePath",
            "name": "basepath",
            "type": "string",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-basepath-string",
            "display": true
          },
          {
            "label": "Proxy Url",
            "name": "proxyUrl",
            "type": "string",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-proxyUrl-string",
            "display": true
          },
          {
            "label": "BaseOptions",
            "name": "baseOptions",
            "type": "json",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-baseOptions-json",
            "display": true
          },
          {
            "label": "Allow Image Uploads",
            "name": "allowImageUploads",
            "type": "boolean",
            "description": "Allow image input. Refer to the <a href=\"https://docs.flowiseai.com/using-flowise/uploads#image\" target=\"_blank\">docs</a> for more details.",
            "default": false,
            "optional": true,
            "id": "chatOpenAI_0-input-allowImageUploads-boolean",
            "display": true
          },
          {
            "label": "Image Resolution",
            "description": "This parameter controls the resolution in which the model views the image.",
            "name": "imageResolution",
            "type": "options",
            "options": [
              {
                "label": "Low",
                "name": "low"
              },
              {
                "label": "High",
                "name": "high"
              },
              {
                "label": "Auto",
                "name": "auto"
              }
            ],
            "default": "low",
            "optional": false,
            "show": {
              "allowImageUploads": true
            },
            "id": "chatOpenAI_0-input-imageResolution-options",
            "display": false
          },
          {
            "label": "Reasoning Effort",
            "description": "Constrains effort on reasoning for reasoning models. Only applicable for o1 and o3 models.",
            "name": "reasoningEffort",
            "type": "options",
            "options": [
              {
                "label": "Low",
                "name": "low"
              },
              {
                "label": "Medium",
                "name": "medium"
              },
              {
                "label": "High",
                "name": "high"
              }
            ],
            "default": "medium",
            "optional": false,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-reasoningEffort-options",
            "display": true
          }
        ],
        "inputAnchors": [
          {
            "label": "Cache",
            "name": "cache",
            "type": "BaseCache",
            "optional": true,
            "id": "chatOpenAI_0-input-cache-BaseCache",
            "display": true
          }
        ],
        "inputs": {
          "cache": "",
          "modelName": "gpt-4.1-mini",
          "temperature": 0.9,
          "streaming": true,
          "maxTokens": "",
          "topP": "",
          "frequencyPenalty": "",
          "presencePenalty": "",
          "timeout": "",
          "strictToolCalling": "",
          "stopSequence": "",
          "basepath": "",
          "proxyUrl": "",
          "baseOptions": "",
          "allowImageUploads": "",
          "imageResolution": "low",
          "reasoningEffort": "medium"
        },
        "outputAnchors": [
          {
            "id": "chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
            "name": "chatOpenAI",
            "label": "ChatOpenAI",
            "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
            "type": "ChatOpenAI | BaseChatModel | BaseLanguageModel | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 675,
      "selected": false,
      "positionAbsolute": {
        "x": -703.0523571575214,
        "y": 79.38293016589085
      },
      "dragging": false
    },
    {
      "id": "chatOpenAI_1",
      "position": {
        "x": 1016.3109790280544,
        "y": -565.9934141727415
      },
      "type": "customNode",
      "data": {
        "id": "chatOpenAI_1",
        "label": "ChatOpenAI",
        "version": 8.2,
        "name": "chatOpenAI",
        "type": "ChatOpenAI",
        "baseClasses": [
          "ChatOpenAI",
          "BaseChatModel",
          "BaseLanguageModel",
          "Runnable"
        ],
        "category": "Chat Models",
        "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "openAIApi"
            ],
            "id": "chatOpenAI_1-input-credential-credential",
            "display": true
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "default": "gpt-4o-mini",
            "id": "chatOpenAI_1-input-modelName-asyncOptions",
            "display": true
          },
          {
            "label": "Temperature",
            "name": "temperature",
            "type": "number",
            "step": 0.1,
            "default": 0.9,
            "optional": true,
            "id": "chatOpenAI_1-input-temperature-number",
            "display": true
          },
          {
            "label": "Streaming",
            "name": "streaming",
            "type": "boolean",
            "default": true,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_1-input-streaming-boolean",
            "display": true
          },
          {
            "label": "Max Tokens",
            "name": "maxTokens",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_1-input-maxTokens-number",
            "display": true
          },
          {
            "label": "Top Probability",
            "name": "topP",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_1-input-topP-number",
            "display": true
          },
          {
            "label": "Frequency Penalty",
            "name": "frequencyPenalty",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_1-input-frequencyPenalty-number",
            "display": true
          },
          {
            "label": "Presence Penalty",
            "name": "presencePenalty",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_1-input-presencePenalty-number",
            "display": true
          },
          {
            "label": "Timeout",
            "name": "timeout",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_1-input-timeout-number",
            "display": true
          },
          {
            "label": "Strict Tool Calling",
            "name": "strictToolCalling",
            "type": "boolean",
            "description": "Whether the model supports the `strict` argument when passing in tools. If not specified, the `strict` argument will not be passed to OpenAI.",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_1-input-strictToolCalling-boolean",
            "display": true
          },
          {
            "label": "Stop Sequence",
            "name": "stopSequence",
            "type": "string",
            "rows": 4,
            "optional": true,
            "description": "List of stop words to use when generating. Use comma to separate multiple stop words.",
            "additionalParams": true,
            "id": "chatOpenAI_1-input-stopSequence-string",
            "display": true
          },
          {
            "label": "BasePath",
            "name": "basepath",
            "type": "string",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_1-input-basepath-string",
            "display": true
          },
          {
            "label": "Proxy Url",
            "name": "proxyUrl",
            "type": "string",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_1-input-proxyUrl-string",
            "display": true
          },
          {
            "label": "BaseOptions",
            "name": "baseOptions",
            "type": "json",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_1-input-baseOptions-json",
            "display": true
          },
          {
            "label": "Allow Image Uploads",
            "name": "allowImageUploads",
            "type": "boolean",
            "description": "Allow image input. Refer to the <a href=\"https://docs.flowiseai.com/using-flowise/uploads#image\" target=\"_blank\">docs</a> for more details.",
            "default": false,
            "optional": true,
            "id": "chatOpenAI_1-input-allowImageUploads-boolean",
            "display": true
          },
          {
            "label": "Image Resolution",
            "description": "This parameter controls the resolution in which the model views the image.",
            "name": "imageResolution",
            "type": "options",
            "options": [
              {
                "label": "Low",
                "name": "low"
              },
              {
                "label": "High",
                "name": "high"
              },
              {
                "label": "Auto",
                "name": "auto"
              }
            ],
            "default": "low",
            "optional": false,
            "show": {
              "allowImageUploads": true
            },
            "id": "chatOpenAI_1-input-imageResolution-options",
            "display": false
          },
          {
            "label": "Reasoning Effort",
            "description": "Constrains effort on reasoning for reasoning models. Only applicable for o1 and o3 models.",
            "name": "reasoningEffort",
            "type": "options",
            "options": [
              {
                "label": "Low",
                "name": "low"
              },
              {
                "label": "Medium",
                "name": "medium"
              },
              {
                "label": "High",
                "name": "high"
              }
            ],
            "default": "medium",
            "optional": false,
            "additionalParams": true,
            "id": "chatOpenAI_1-input-reasoningEffort-options",
            "display": true
          }
        ],
        "inputAnchors": [
          {
            "label": "Cache",
            "name": "cache",
            "type": "BaseCache",
            "optional": true,
            "id": "chatOpenAI_1-input-cache-BaseCache",
            "display": true
          }
        ],
        "inputs": {
          "cache": "",
          "modelName": "gpt-4o-mini",
          "temperature": 0.9,
          "streaming": true,
          "maxTokens": "",
          "topP": "",
          "frequencyPenalty": "",
          "presencePenalty": "",
          "timeout": "",
          "strictToolCalling": "",
          "stopSequence": "",
          "basepath": "",
          "proxyUrl": "",
          "baseOptions": "",
          "allowImageUploads": "",
          "imageResolution": "low",
          "reasoningEffort": "medium"
        },
        "outputAnchors": [
          {
            "id": "chatOpenAI_1-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
            "name": "chatOpenAI",
            "label": "ChatOpenAI",
            "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
            "type": "ChatOpenAI | BaseChatModel | BaseLanguageModel | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 675,
      "selected": false,
      "positionAbsolute": {
        "x": 1016.3109790280544,
        "y": -565.9934141727415
      },
      "dragging": false
    }
  ],
  "edges": [
    {
      "source": "calculator_0",
      "sourceHandle": "calculator_0-output-calculator-Calculator|Tool|StructuredTool|Runnable",
      "target": "worker_0",
      "targetHandle": "worker_0-input-tools-Tool",
      "type": "buttonedge",
      "id": "calculator_0-calculator_0-output-calculator-Calculator|Tool|StructuredTool|Runnable-worker_0-worker_0-input-tools-Tool"
    },
    {
      "source": "codeInterpreterE2B_0",
      "sourceHandle": "codeInterpreterE2B_0-output-codeInterpreterE2B-CodeInterpreter|Tool|StructuredTool|Runnable",
      "target": "worker_1",
      "targetHandle": "worker_1-input-tools-Tool",
      "type": "buttonedge",
      "id": "codeInterpreterE2B_0-codeInterpreterE2B_0-output-codeInterpreterE2B-CodeInterpreter|Tool|StructuredTool|Runnable-worker_1-worker_1-input-tools-Tool"
    },
    {
      "source": "writeFile_0",
      "sourceHandle": "writeFile_0-output-writeFile-WriteFile|Tool|StructuredTool|Runnable",
      "target": "worker_2",
      "targetHandle": "worker_2-input-tools-Tool",
      "type": "buttonedge",
      "id": "writeFile_0-writeFile_0-output-writeFile-WriteFile|Tool|StructuredTool|Runnable-worker_2-worker_2-input-tools-Tool"
    },
    {
      "source": "supervisor_0",
      "sourceHandle": "supervisor_0-output-supervisor-Supervisor",
      "target": "worker_0",
      "targetHandle": "worker_0-input-supervisor-Supervisor",
      "type": "buttonedge",
      "id": "supervisor_0-supervisor_0-output-supervisor-Supervisor-worker_0-worker_0-input-supervisor-Supervisor"
    },
    {
      "source": "supervisor_0",
      "sourceHandle": "supervisor_0-output-supervisor-Supervisor",
      "target": "worker_1",
      "targetHandle": "worker_1-input-supervisor-Supervisor",
      "type": "buttonedge",
      "id": "supervisor_0-supervisor_0-output-supervisor-Supervisor-worker_1-worker_1-input-supervisor-Supervisor"
    },
    {
      "source": "supervisor_0",
      "sourceHandle": "supervisor_0-output-supervisor-Supervisor",
      "target": "worker_2",
      "targetHandle": "worker_2-input-supervisor-Supervisor",
      "type": "buttonedge",
      "id": "supervisor_0-supervisor_0-output-supervisor-Supervisor-worker_2-worker_2-input-supervisor-Supervisor"
    },
    {
      "source": "chatOpenAI_0",
      "sourceHandle": "chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
      "target": "supervisor_0",
      "targetHandle": "supervisor_0-input-model-BaseChatModel",
      "type": "buttonedge",
      "id": "chatOpenAI_0-chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable-supervisor_0-supervisor_0-input-model-BaseChatModel"
    },
    {
      "source": "chatOpenAI_1",
      "sourceHandle": "chatOpenAI_1-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
      "target": "worker_2",
      "targetHandle": "worker_2-input-model-BaseChatModel",
      "type": "buttonedge",
      "id": "chatOpenAI_1-chatOpenAI_1-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable-worker_2-worker_2-input-model-BaseChatModel"
    }
  ]
}